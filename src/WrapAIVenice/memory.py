# memory.py
"""
Conversation memory manager for AI chat sessions.

Includes:
- `ConversationMemory`: Tracks messages, manages token limits, trims history,
  and supports system prompt updates and summarization.
"""

from .utils.tokens_char import count_characters_and_tokens


class ConversationMemory:
    def __init__(self, system_prompt="", max_tokens=8000, token_buffer=512):
        self.messages = []
        self.max_tokens = max_tokens
        self.token_buffer = token_buffer
        self.current_tokens = 0

        if system_prompt:
            self.add_message("system", system_prompt)

    def update_system_prompt(self, prompt):
        if self.messages and self.messages[0]["role"] == "system":
            self.messages[0]["content"] = prompt
        else:
            self.messages.insert(0, {"role": "system", "content": prompt})
        self.current_tokens = sum(self.calculate_tokens(msg["content"]) for msg in self.messages)

    def reset(self):
        self.messages = []
        self.current_tokens = 0

    def add_message(self, role, content):
        """Add message to memory with automatic trimming"""
        new_msg = {"role": role, "content": content}
        tokens = self.calculate_tokens(content)

        if self._will_exceed_limit(tokens):
            self.trim_messages(tokens)

        self.messages.append(new_msg)
        self.current_tokens += tokens

    def trim_messages(self, incoming_tokens=0):
        """Remove oldest non-system messages until under token limit"""
        target = self.max_tokens - self.token_buffer - incoming_tokens
        while self.current_tokens > target and len(self.messages) > 1:
            removed = self.messages.pop(1)  # Keep system prompt
            self.current_tokens -= self.calculate_tokens(removed["content"])

    def reset_with_summary(self, summary):
        """Replace memory with summary and preserve recent context.

        Expects `summary` to be generated by an external summarizer (e.g., VeniceChatPrompt).
        """
        system_msg = self.messages[0] if self.messages else {"role": "system", "content": ""}

        # Preserve last 2 exchanges
        recent = self.messages[-4:] if len(self.messages) >=4 else self.messages

        # New message list
        self.messages = [
                            {
                                "role": system_msg["role"],
                                "content": f"{system_msg['content']}\nSUMMARY: {summary}"
                            }
                        ] + recent

        # Recalculate tokens
        self.current_tokens = sum(
            self.calculate_tokens(msg["content"])
            for msg in self.messages
        )

    def calculate_tokens(self, text):
        _, tokens = count_characters_and_tokens(text)
        return tokens

    def _will_exceed_limit(self, incoming):
        return (self.current_tokens + incoming) > (self.max_tokens - self.token_buffer)

    @property
    def message_history(self):
        return self.messages.copy()

    @property
    def token_count(self):
        return self.current_tokens
